[data]
; Path to training and test data.
; Each dataset should have an <images>-dir and an <masks>-dir with image and mask files.
; Images and masks (labels) must have the same filename.
path_train=PATH/TO/TRAIN_DATA
path_test=PATH/TO/TEST_DATA
; Path for saving checkpoints if enabled (see callbacks)
path_ckpt=PATH/TO/CHECKPOINTS
; Split to use for defining an validation set from training data.
split_train_val=0.8
; If true, all loaded images and masks will be kept in memory.
keep_in_memory=True
; Shuffle data if true
shuffle=False

[preprocess]
; Scale image to img_w x img_h
img_w=512
img_h=512

[model]
; Number of image-channels.
input_dim=1
; Number of conv-kernels in the first level of the unet.
conv_dim=64
; Kernel-size of the conv-layers.
kernel_size=3
; Use dropout to handle overfitting, dropout=0.0 -> disabled
dropout=0.0
; Padding option, usual <same> if we want to keep image dimensions
padding=same

[training]
; Either 'cpu' or 'cuda' (for gpu)
device=cuda
; Number of epochs
epochs=10
; Batch-size depends on GPU VRam (if device=cuda)
batch_size=1
; Learning rate, usual 1e-3 or 1e-4 for training from scratch
learning_rate=1e-3
; See https://pytorch.org/docs/stable/optim.html#algorithms for full list
optimizer=Adam
; See https://pytorch.org/docs/stable/nn.html#loss-functions for full list
loss=BCEWithLogitsLoss
; Choose from [accuracy, jaccard, f1score]
metric=jaccard

[callbacks]
; Save checkpoints after every epoch
checkpoints=True
; Save the best_weight
save_best=True

[misc]
; See https://pytorch.org/docs/stable/amp.html
enable_amp=True



